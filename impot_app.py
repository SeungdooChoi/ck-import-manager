import streamlit as st
import pandas as pd
from sqlalchemy import text
from datetime import datetime
import time
import pytz
import re
import io
import json

# ==========================================
# 0. ê¸°ë³¸ ì„¤ì • ë° ìŠ¤íƒ€ì¼
# ==========================================
st.set_page_config(page_title="ìˆ˜ì…ì§„í–‰ê´€ë¦¬ (CK Global)", layout="wide")
KST = pytz.timezone('Asia/Seoul')

def get_kst_today():
    return datetime.now(KST).date()

st.markdown("""
<style>
    .block-container { max-width: 98% !important; padding-top: 1rem; }
    
    /* ìƒíƒœ ë°°ì§€ ìŠ¤íƒ€ì¼ */
    .status-badge { padding: 2px 6px; border-radius: 4px; font-weight: bold; font-size: 0.8em; }
    .status-pending { background-color: #fff3bf; color: #f08c00; }
    .status-arrived { background-color: #d3f9d8; color: #2b8a3e; }
    .status-canceled { background-color: #ffe3e3; color: #c92a2a; }

    /* ë©”íŠ¸ë¦­ ë°•ìŠ¤ ìŠ¤íƒ€ì¼ */
    .metric-box {
        background-color: #f8f9fa;
        border: 1px solid #dee2e6;
        padding: 10px;
        border-radius: 8px;
        text-align: center;
        font-size: 14px;
        box-shadow: 0 1px 2px rgba(0,0,0,0.05);
    }
    
    /* í¼ í—¤ë” ìŠ¤íƒ€ì¼ */
    .form-header {
        font-weight: 700;
        font-size: 1.1em;
        margin-top: 20px;
        margin-bottom: 10px;
        border-bottom: 2px solid #e9ecef;
        padding-bottom: 5px;
        color: #495057;
    }
    
    /* ë°ì´í„°í”„ë ˆì„ ìŠ¤íƒ€ì¼ */
    .stDataFrame { font-size: 12px; }
</style>
""", unsafe_allow_html=True)

# DB ì—°ê²° ë° ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸
try:
    conn = st.connection("supabase", type="sql")
    with conn.session as s:
        # ëª¨ë“  í•„ìš”í•œ ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ì¶”ê°€
        cols_to_add = [
            ("ck_code", "TEXT"), ("size", "TEXT"), ("unit_price", "NUMERIC"), ("supplier", "TEXT"),
            ("global_code", "TEXT"), ("doojin_code", "TEXT"), ("agency", "TEXT"), ("agency_contract", "TEXT"),
            ("origin", "TEXT"), ("packing", "TEXT"), ("open_qty", "NUMERIC"), ("doc_qty", "NUMERIC"),
            ("box_qty", "NUMERIC"), ("unit2", "TEXT"), ("open_amount", "NUMERIC"), ("doc_amount", "NUMERIC"),
            ("tt_check", "TEXT"), ("bank", "TEXT"), ("usance", "TEXT"), ("at_sight", "TEXT"),
            ("open_date", "DATE"), ("lc_no", "TEXT"), ("invoice_no", "TEXT"), ("bl_no", "TEXT"),
            ("lg_no", "TEXT"), ("insurance", "TEXT"), ("customs_broker_date", "DATE"), ("etd", "DATE"),
            ("arrival_date", "DATE"), ("warehouse", "TEXT"), ("actual_in_qty", "NUMERIC"), ("destination", "TEXT"),
            ("doc_acceptance", "DATE"), ("acceptance_rate", "NUMERIC"), ("maturity_date", "DATE"),
            ("ext_maturity_date", "DATE"), ("acceptance_fee", "NUMERIC"), ("discount_fee", "NUMERIC"),
            ("payment_date", "DATE"), ("payment_amount", "NUMERIC"), ("exchange_rate", "NUMERIC"),
            ("balance", "NUMERIC"), ("avg_exchange_rate", "NUMERIC"),
            # í†µê´€ ë° ì‹ ê³  ì •ë³´ (JSONBë¡œ ì €ì¥í•˜ì—¬ Nê°œ ë°ì´í„° ì§€ì›)
            ("clearance_info", "JSONB"), ("declaration_info", "JSONB")
        ]
        for col_name, col_type in cols_to_add:
            s.execute(text(f"ALTER TABLE import_schedules ADD COLUMN IF NOT EXISTS {col_name} {col_type};"))
        s.commit()
except Exception as e:
    st.error(f"DB ì—°ê²° ì˜¤ë¥˜: .streamlit/secrets.tomlì„ í™•ì¸í•˜ì„¸ìš”.\n{e}")
    st.stop()

# ==========================================
# 1. ë°ì´í„° ì¡°íšŒ ë° ì•¡ì…˜ í•¨ìˆ˜
# ==========================================

@st.cache_data(ttl=600)
def get_products_df():
    """DBì— ë“±ë¡ëœ í’ˆëª© ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ"""
    with conn.session as s:
        df = pd.DataFrame(s.execute(text("SELECT product_id, product_name, product_code, category, unit FROM products WHERE is_active = TRUE ORDER BY category, product_name")).fetchall())
        if not df.empty:
            df.columns = ['ID', 'í’ˆëª©ëª…', 'í’ˆëª©ì½”ë“œ', 'ì¹´í…Œê³ ë¦¬', 'ë‹¨ìœ„']
        return df

def register_new_product(code, name, cat, unit):
    """ì‹ ê·œ í’ˆëª© DB ë“±ë¡"""
    try:
        with conn.session as s:
            chk = s.execute(text("SELECT 1 FROM products WHERE product_code = :code"), {"code": code}).fetchone()
            if chk: return False, "ì´ë¯¸ ì¡´ì¬í•˜ëŠ” í’ˆëª©ì½”ë“œì…ë‹ˆë‹¤."
            s.execute(text("""
                INSERT INTO products (product_code, product_name, category, unit, is_active)
                VALUES (:code, :name, :cat, :unit, TRUE)
            """), {"code": code, "name": name, "cat": cat, "unit": unit})
            s.commit()
        get_products_df.clear() # ìºì‹œ ì´ˆê¸°í™”
        return True, "í’ˆëª© ë“±ë¡ ì™„ë£Œ"
    except Exception as e: return False, str(e)

def get_full_schedule_data(status_filter='ALL'):
    """ëª¨ë“  ìƒì„¸ ì •ë³´ë¥¼ í¬í•¨í•œ ë°ì´í„° ì¡°íšŒ"""
    with conn.session as s:
        # ëª¨ë“  ì»¬ëŸ¼ ì„ íƒ (LEFT JOINìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ì œí’ˆ ì •ë³´ ì—†ì–´ë„ ì¡°íšŒ ê°€ëŠ¥í•˜ë„ë¡)
        base_sql = """
            SELECT s.*, p.product_name, p.product_code as db_prod_code, p.unit as p_unit
            FROM import_schedules s
            LEFT JOIN products p ON s.product_id = p.product_id
        """
        if status_filter != 'ALL':
            base_sql += f" WHERE s.status = '{status_filter}'"
        
        base_sql += " ORDER BY s.expected_date ASC, s.id DESC"
        
        df = pd.DataFrame(s.execute(text(base_sql)).fetchall())
        return df

def save_full_schedule(data, sid=None):
    """ìƒì„¸ ì •ë³´ ì €ì¥ (INSERT or UPDATE)"""
    try:
        with conn.session as s:
            cols = [
                'product_id', 'expected_date', 'quantity', 'note', 'status', 'size', 'supplier', 'unit_price', 'ck_code',
                'global_code', 'doojin_code', 'agency', 'agency_contract', 'origin', 'packing', 
                'open_qty', 'doc_qty', 'box_qty', 'unit2', 'open_amount', 'doc_amount',
                'tt_check', 'bank', 'usance', 'at_sight', 'open_date', 'lc_no', 'invoice_no', 'bl_no', 'lg_no', 'insurance',
                'customs_broker_date', 'etd', 'arrival_date', 'warehouse', 'actual_in_qty', 'destination',
                'doc_acceptance', 'acceptance_rate', 'maturity_date', 'ext_maturity_date', 'acceptance_fee', 'discount_fee',
                'payment_date', 'payment_amount', 'exchange_rate', 'balance', 'avg_exchange_rate',
                'clearance_info', 'declaration_info'
            ]
            
            # ìˆ«ìí˜• ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ (0ìœ¼ë¡œ ì²˜ë¦¬í•  ê²ƒë“¤)
            numeric_cols = ['quantity', 'unit_price', 'open_qty', 'doc_qty', 'box_qty', 'open_amount', 'doc_amount', 
                            'actual_in_qty', 'acceptance_rate', 'acceptance_fee', 'discount_fee', 'payment_amount', 
                            'exchange_rate', 'balance', 'avg_exchange_rate']
            
            # JSON ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
            json_cols = ['clearance_info', 'declaration_info']

            params = {}
            for k in cols:
                val = data.get(k)
                if k in numeric_cols:
                    if val is None or str(val).strip() == '':
                        params[k] = 0
                    else:
                        try: params[k] = float(str(val).replace(',', '').strip())
                        except: params[k] = 0
                elif k in json_cols:
                    # JSON ë°ì´í„° ì²˜ë¦¬
                    if isinstance(val, (list, dict)):
                        params[k] = json.dumps(val, ensure_ascii=False)
                    elif isinstance(val, str) and (val.startswith('[') or val.startswith('{')):
                        params[k] = val # ì´ë¯¸ JSON ë¬¸ìì—´ì¸ ê²½ìš°
                    else:
                        params[k] = '[]' # ê¸°ë³¸ê°’
                else:
                    if val is None or str(val).strip() == '' or str(val).lower() == 'nan':
                        params[k] = None
                    else:
                        params[k] = val
            
            # status ê°’ ê°•ì œ ì„¤ì • (ê°’ì´ ì—†ìœ¼ë©´ PENDING)
            if not params.get('status'):
                params['status'] = 'PENDING'

            if sid:
                # UPDATE
                set_clause = ", ".join([f"{col} = :{col}::jsonb" if col in json_cols else f"{col} = :{col}" for col in cols])
                sql = f"UPDATE import_schedules SET {set_clause} WHERE id = :id"
                params['id'] = sid
                s.execute(text(sql), params)
                msg = "ìˆ˜ì • ì™„ë£Œ"
            else:
                # INSERT
                col_str = ", ".join(cols)
                val_str = ", ".join([f":{col}::jsonb" if col in json_cols else f":{col}" for col in cols])
                sql = f"INSERT INTO import_schedules ({col_str}) VALUES ({val_str})"
                s.execute(text(sql), params)
                msg = "ë“±ë¡ ì™„ë£Œ"
                
            s.commit()
        return True, msg
    except Exception as e: return False, str(e)

def delete_schedule(sid):
    try:
        with conn.session as s:
            s.execute(text("DELETE FROM import_schedules WHERE id = :sid"), {"sid": sid})
            s.commit()
        return True, "ì‚­ì œ ì™„ë£Œ"
    except Exception as e: return False, str(e)

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
def safe_date_parse(val):
    if pd.isna(val) or str(val).strip() == '': return None
    try:
        if isinstance(val, datetime): return val.strftime('%Y-%m-%d')
        s_val = str(val).strip()
        # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì§€ì›
        if re.match(r'^\d{2}/\d{2}/\d{2}$', s_val): # 25/01/01
            dt = datetime.strptime(s_val, "%y/%m/%d")
            if dt.year < 2000: dt = dt.replace(year=dt.year+2000)
            return dt.strftime('%Y-%m-%d')
        if re.match(r'^\d{4}-\d{2}-\d{2}$', s_val): return datetime.strptime(s_val, "%Y-%m-%d").strftime('%Y-%m-%d')
        if re.match(r'^\d{4}\.\d{2}\.\d{2}$', s_val): return datetime.strptime(s_val, "%Y.%m.%d").strftime('%Y-%m-%d')
        if re.match(r'^\d{8}$', s_val): return datetime.strptime(s_val, "%Y%m%d").strftime('%Y-%m-%d')
        return pd.to_datetime(val).strftime('%Y-%m-%d')
    except: return None

def safe_float_parse(val):
    if pd.isna(val) or str(val).strip() == '': return 0.0
    try: return float(str(val).replace(',', '').replace(' ', '').strip())
    except: return 0.0

def parse_import_full_excel(df):
    """
    'ìˆ˜ì…' íƒ­(ìƒì„¸ ì¥ë¶€) êµ¬ì¡°ì˜ ì—‘ì…€/CSV íŒŒì¼ íŒŒì‹±
    í—¤ë”ë¥¼ ì°¾ì•„ ì»¬ëŸ¼ ë§¤í•‘ í›„ ë°ì´í„° ì¶”ì¶œ
    """
    valid_data = []
    errors = []
    
    p_df = get_products_df()
    if p_df.empty: return [], ["ì‹œìŠ¤í…œì— ë“±ë¡ëœ í’ˆëª©ì´ ì—†ìŠµë‹ˆë‹¤."]
    product_map = {str(row['í’ˆëª©ëª…']).replace(" ", "").lower(): row['ID'] for _, row in p_df.iterrows()}
    
    # 1. í—¤ë” í–‰ ì°¾ê¸° (ìŠ¤ì½”ì–´ë§ ë°©ì‹ ê°•í™”)
    keywords = ['CK', 'ê´€ë¦¬ë²ˆí˜¸', 'í’ˆëª…', 'ìˆ˜ëŸ‰', 'ë‹¨ê°€', 'ê¸€ë¡œë²Œ', 'ë‘ì§„', 'ì…ê³ ì¼', 'ETA']
    
    # ë¬¸ìì—´ ì •ì œ í—¬í¼ (ê³µë°±, ì¤„ë°”ê¿ˆ ì œê±°)
    def clean_str(s):
        return str(s).replace('\n', '').replace('\r', '').replace(' ', '').upper().strip()

    # í˜„ì¬ ì»¬ëŸ¼ëª…ì´ í—¤ë”ì¸ì§€ ë¨¼ì € í™•ì¸
    col_str = "".join([clean_str(c) for c in df.columns])
    score_cols = 0
    for k in keywords:
        if k in col_str: score_cols += 1
    
    # í•„ìˆ˜ í‚¤ì›Œë“œ (CK/ê´€ë¦¬ë²ˆí˜¸ + í’ˆëª…) í™•ì¸
    has_mandatory = ('CK' in col_str or 'ê´€ë¦¬ë²ˆí˜¸' in col_str) and 'í’ˆëª…' in col_str

    data_df = pd.DataFrame()
    header_row_idx = -1

    if score_cols >= 2 and has_mandatory:
        data_df = df
    else:
        if df.empty: return [], ["íŒŒì¼ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."]

        max_score = 0
        for i in range(min(20, len(df))):
            row_vals = [clean_str(x) for x in df.iloc[i].values if pd.notna(x)]
            row_str = "".join(row_vals)
            score = 0
            for k in keywords:
                if k in row_str: score += 1
            
            row_has_mandatory = ('CK' in row_str or 'ê´€ë¦¬ë²ˆí˜¸' in row_str) and 'í’ˆëª…' in row_str
            
            if score > max_score and score >= 2 and row_has_mandatory:
                max_score = score
                header_row_idx = i
                
        if header_row_idx != -1:
            df.columns = df.iloc[header_row_idx]
            data_df = df.iloc[header_row_idx+1:].reset_index(drop=True)
        else:
            return [], ["í—¤ë”('CK', 'í’ˆëª…' ë“±)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ìƒìœ„ 20í–‰ ê²€ìƒ‰ ì‹¤íŒ¨)"]

    # ì»¬ëŸ¼ ì´ë¦„ ì •ì œ (ëª¨ë“  ê³µë°±/ì¤„ë°”ê¿ˆ ì œê±°)
    data_df.columns = [clean_str(c) for c in data_df.columns]
    cols = list(data_df.columns)
    
    # 3. ì»¬ëŸ¼ ë§¤í•‘ (ê³µë°± ì œê±°ëœ í‚¤ì›Œë“œ ì‚¬ìš©)
    def find_col(keywords):
        for c in cols:
            # cëŠ” ì´ë¯¸ clean_str ì²˜ë¦¬ë¨
            for k in keywords:
                k_clean = k.replace(" ", "").upper()
                if k_clean in c: return c
        return None

    # í‚¤ì›Œë“œë„ ê³µë°± ì—†ì´ ê²€ìƒ‰
    col_map = {
        'ck': find_col(['CK', 'ê´€ë¦¬ë²ˆí˜¸']), 'global': find_col(['ê¸€ë¡œë²Œ']), 'doojin': find_col(['ë‘ì§„']),
        'agency': find_col(['ëŒ€í–‰']), 'agency_contract': find_col(['ëŒ€í–‰ê³„ì•½ì„œ']),
        'supplier': find_col(['ìˆ˜ì¶œì', 'ìˆ˜ì…ì']), 'origin': find_col(['ì›ì‚°ì§€']), 'name': find_col(['í’ˆëª…']),
        'size': find_col(['ì‚¬ì´ì¦ˆ']), 'packing': find_col(['Packing']), 'open_qty': find_col(['ì˜¤í”ˆìˆ˜ëŸ‰']),
        'unit': find_col(['ë‹¨ìœ„']), 'doc_qty': find_col(['ì„œë¥˜ìˆ˜ëŸ‰']), 'box_qty': find_col(['ë°•ìŠ¤ìˆ˜ëŸ‰']),
        'price': find_col(['ë‹¨ê°€']), 'open_amt': find_col(['ì˜¤í”ˆê¸ˆì•¡']), 'doc_amt': find_col(['ì„œë¥˜ê¸ˆì•¡']),
        'tt': find_col(['T/T']), 'bank': find_col(['ì€í–‰']), 'usance': find_col(['Usance']), 'at_sight': find_col(['AtSight']),
        'open_date': find_col(['ê°œì„¤ì¼']), 'lc_no': find_col(['LCNo', 'L/C']), 'inv_no': find_col(['Invoice']),
        'bl_no': find_col(['BLNo', 'B/L']), 'lg_no': find_col(['LG', 'L/G']), 'insurance': find_col(['ë³´í—˜']),
        'broker_date': find_col(['ê´€ì„¸ì‚¬', 'ê´€ì„¸ì‚¬ë°œì†¡ì¼']), 'etd': find_col(['ETD']), 'eta': find_col(['ETA']),
        'arrival_date': find_col(['ì…ê³ ì¼']), 'wh': find_col(['ì°½ê³ ']), 'real_in_qty': find_col(['ì‹¤ì…ê³ ', 'ì‹¤ì…ê³ ìˆ˜ëŸ‰']),
        'dest': find_col(['ì°©ì§€']), 'note': find_col(['ë¹„ê³ ']), 'doc_acc': find_col(['ì„œë¥˜ì¸ìˆ˜']),
        'acc_rate': find_col(['ì¸ìˆ˜ìˆ˜ìˆ˜ë£Œìœ¨']), 'mat_date': find_col(['ë§Œê¸°ì¼']), 'ext_date': find_col(['ì—°ì¥ë§Œê¸°ì¼']),
        'acc_fee': find_col(['ì¸ìˆ˜ìˆ˜ìˆ˜ë£Œ']), 'dis_fee': find_col(['ì¸ìˆ˜í• ì¸ë£Œ']), 'pay_date': find_col(['ê²°ì œì¼']),
        'pay_amt': find_col(['ê²°ì œê¸ˆì•¡']), 'ex_rate': find_col(['í™˜ìœ¨']), 'balance': find_col(['ì”ì•¡']), 'avg_ex': find_col(['í‰ê· í™˜ìœ¨'])
    }
    
    # 'agency' ì¬í™•ì¸
    if col_map['agency'] and 'ê³„ì•½ì„œ' in str(col_map['agency']):
        col_map['agency'] = None
        for c in cols:
            if 'ëŒ€í–‰' in c and 'ê³„ì•½ì„œ' not in c: col_map['agency'] = c; break

    try:
        if col_map['price']:
            idx = cols.index(col_map['price'])
            col_map['unit2'] = cols[idx+1] if idx + 1 < len(cols) else None
        else: col_map['unit2'] = None
    except: col_map['unit2'] = None

    # ë°ì´í„° ì¶”ì¶œ
    for idx, row in data_df.iterrows():
        if not col_map['name']: continue
        name_val = str(row.get(col_map['name'], '')).strip()
        if not name_val or name_val.lower() == 'nan': continue
        
        search_key = name_val.replace(" ", "").lower()
        pid = product_map.get(search_key)
        ck_val = str(row.get(col_map['ck'], '')).strip() if col_map['ck'] else ""
        if ck_val.lower() == 'nan': ck_val = ""
        
        if not pid:
            errors.append(f"[í–‰ {idx+2}] ì•Œ ìˆ˜ ì—†ëŠ” í’ˆëª©: '{name_val}' (CK: {ck_val})")
            continue
            
        try:
            # í—¬í¼ í•¨ìˆ˜
            def get_val(key, parser=str):
                col = col_map.get(key)
                if col:
                    val = row.get(col)
                    return parser(val)
                return 0.0 if parser == safe_float_parse else (None if parser == safe_date_parse else '')

            # í†µê´€ ì •ë³´ ì¶”ì¶œ
            clearance_list = []
            for i in range(1, 11):
                suffix = str(i) if i > 1 else ""
                c_date_col = find_col([f"í†µê´€ì¼ì{suffix}"])
                c_qty_col = find_col([f"í†µê´€ìˆ˜ëŸ‰{suffix}"])
                c_rate_col = find_col([f"í†µê´€í™˜ìœ¨{suffix}"])
                
                if c_date_col or c_qty_col:
                    d_val = safe_date_parse(row.get(c_date_col)) if c_date_col else None
                    q_val = safe_float_parse(row.get(c_qty_col)) if c_qty_col else 0.0
                    r_val = safe_float_parse(row.get(c_rate_col)) if c_rate_col else 0.0
                    if d_val or q_val > 0:
                        clearance_list.append({"date": d_val, "qty": q_val, "rate": r_val})

            # ìˆ˜ì…ì‹ ê³  ì •ë³´ ì¶”ì¶œ
            declaration_list = []
            for i in range(1, 11):
                suffix = str(i) if i > 1 else ""
                d_date_col = find_col([f"ì‹ ê³ ì¼{suffix}"])
                d_no_col = find_col([f"ì‹ ê³ ë²ˆí˜¸{suffix}"])
                
                if d_date_col or d_no_col:
                    date_val = safe_date_parse(row.get(d_date_col)) if d_date_col else None
                    no_val = str(row.get(d_no_col, '')).strip() if d_no_col else ''
                    if date_val or no_val:
                        declaration_list.append({"date": date_val, "no": no_val})

            data = {
                'product_id': pid, 'ck_code': ck_val,
                'global_code': get_val('global'), 'doojin_code': get_val('doojin'),
                'agency': get_val('agency'), 'agency_contract': get_val('agency_contract'),
                'supplier': get_val('supplier'), 'origin': get_val('origin'),
                'size': get_val('size'), 'packing': get_val('packing'),
                'open_qty': get_val('open_qty', safe_float_parse),
                'quantity': get_val('open_qty', safe_float_parse),
                'doc_qty': get_val('doc_qty', safe_float_parse),
                'box_qty': get_val('box_qty', safe_float_parse),
                'unit2': get_val('unit2'),
                'unit_price': get_val('price', safe_float_parse),
                'open_amount': get_val('open_amt', safe_float_parse),
                'doc_amount': get_val('doc_amt', safe_float_parse),
                'tt_check': get_val('tt'), 'bank': get_val('bank'),
                'usance': get_val('usance'), 'at_sight': get_val('at_sight'),
                'open_date': get_val('open_date', safe_date_parse),
                'lc_no': get_val('lc_no'), 'invoice_no': get_val('inv_no'),
                'bl_no': get_val('bl_no'), 'lg_no': get_val('lg_no'), 'insurance': get_val('insurance'),
                'customs_broker_date': get_val('broker_date', safe_date_parse),
                'etd': get_val('etd', safe_date_parse),
                'expected_date': get_val('eta', safe_date_parse) or get_kst_today(),
                'arrival_date': get_val('arrival_date', safe_date_parse),
                'warehouse': get_val('wh'), 
                'actual_in_qty': get_val('real_in_qty', safe_float_parse),
                'destination': get_val('dest'), 'note': get_val('note'),
                'doc_acceptance': get_val('doc_acc', safe_date_parse),
                'acceptance_rate': get_val('acc_rate', safe_float_parse),
                'maturity_date': get_val('mat_date', safe_date_parse),
                'ext_maturity_date': get_val('ext_date', safe_date_parse),
                'acceptance_fee': get_val('acc_fee', safe_float_parse),
                'discount_fee': get_val('dis_fee', safe_float_parse),
                'payment_date': get_val('pay_date', safe_date_parse),
                'payment_amount': get_val('pay_amt', safe_float_parse),
                'exchange_rate': get_val('ex_rate', safe_float_parse),
                'balance': get_val('balance', safe_float_parse),
                'avg_exchange_rate': get_val('avg_ex', safe_float_parse),
                'clearance_info': clearance_list,
                'declaration_info': declaration_list,
                'status': 'PENDING'
            }
            data['unit'] = str(row.get(col_map.get('unit'), '')).strip() if col_map.get('unit') else ''

            for k, v in data.items():
                if isinstance(v, str) and (v.lower() == 'nan' or v.lower() == 'nat'): data[k] = ''
            valid_data.append(data)
        except Exception as e:
            errors.append(f"[í–‰ {idx+2}] ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            
    return valid_data, errors

# ==========================================
# 2. ë©”ì¸ UI êµ¬ì„±
# ==========================================

st.title("ğŸš¢ ìˆ˜ì… ê´€ë¦¬ ì‹œìŠ¤í…œ")

tab_status, tab_ledger, tab_manage, tab_product = st.tabs(["ğŸ“Š ìˆ˜ì…ì§„í–‰ìƒí™©", "ğŸ“’ ìˆ˜ì…ì¥ë¶€ (ìƒì„¸)", "ğŸ“ ë“±ë¡ ë° ê´€ë¦¬", "ğŸ“¦ í’ˆëª© ê´€ë¦¬"])

# --- TAB 1: ìˆ˜ì…ì§„í–‰ìƒí™© (HTML ë·°) ---
with tab_status:
    st.markdown("### ğŸ“… ìˆ˜ì… ì§„í–‰ í˜„í™©íŒ")
    
    df = get_full_schedule_data('ALL')
    
    if df.empty:
        st.info("ë“±ë¡ëœ ìˆ˜ì… ì¼ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        df['eta_str'] = pd.to_datetime(df['expected_date']).dt.strftime('%y/%m/%d')
        grouped = df.groupby('eta_str', sort=False)
        
        # HTML ë Œë”ë§ - ë“¤ì—¬ì“°ê¸° ì œê±°
        html_content = """<table style="width:100%; border-collapse: collapse; font-size:13px; text-align:center;"><thead><tr style="background-color:#f1f3f5; border-bottom:2px solid #dee2e6;"><th style="padding:8px;">ì…í•­ì¼</th><th style="padding:8px;">ê³µê¸‰ì‚¬</th><th style="padding:8px;">í’ˆëª…</th><th style="padding:8px;">CK</th><th style="padding:8px;">ì‚¬ì´ì¦ˆ</th><th style="padding:8px;">ë‹¨ê°€</th><th style="padding:8px;">ìˆ˜ëŸ‰</th><th style="padding:8px;">ìƒíƒœ</th></tr></thead><tbody>"""
        
        for date_str, group in grouped:
            html_content += f"""<tr style="background-color:#e7f5ff; border-top:1px solid #dee2e6; border-bottom:1px solid #dee2e6;"><td colspan="8" style="padding:6px; font-weight:bold; text-align:left; padding-left:15px;">ğŸ“… {date_str} (ì´ {len(group)}ê±´)</td></tr>"""
            
            for _, row in group.iterrows():
                status_cls = "status-pending" if row['status'] == 'PENDING' else ("status-arrived" if row['status'] == 'ARRIVED'